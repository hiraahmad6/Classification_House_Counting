{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CLASSIFICATION.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPlHeh6OS68vEp8/Y77VPLv"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"fXZar_uRGnxm","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.autograd import Variable\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-BWtcrPtHkXB","colab_type":"code","colab":{}},"source":["data_dir = ''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NqqD42TTLsUL","colab_type":"code","colab":{}},"source":["class ImageFolderWithPaths(datasets.ImageFolder):\n","    \"\"\"Custom dataset that includes image file paths. Extends\n","    torchvision.datasets.ImageFolder\n","    \"\"\"\n","\n","    # override the __getitem__ method. this is the method that dataloader calls\n","    def __getitem__(self, index):\n","        # this is what ImageFolder normally returns \n","        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n","        # the image file path\n","        path = self.imgs[index][0]\n","        # make a new tuple that includes original and the path\n","        tuple_with_path = (original_tuple + (path,))\n","        return tuple_with_path"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GpUBeZ8aLvY5","colab_type":"code","colab":{}},"source":["#Define transforms for the training data and testing data\n","train_transforms = transforms.Compose([\n","                       transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225]),\n","                   ])\n","\n","test_transforms = transforms.Compose([\n","                       transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225]),\n","                   ])\n","\n","#pass transform here-in\n","train_data = ImageFolderWithPaths(data_dir + 'TRAIN_DATA', transform=train_transforms)\n","test_data = ImageFolderWithPaths(data_dir + 'TEST_DATA', transform=test_transforms)\n","\n","#data loaders\n","trainloader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n","testloader = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=True)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ggMT4th3MB7a","colab_type":"code","colab":{}},"source":["print(\"Classes: \")\n","class_names = train_data.classes\n","print(class_names)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PuktcGICOFIA","colab_type":"code","colab":{}},"source":["def imshow(inp, title=None):\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    plt.axis('off')\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)\n","\n","def show_databatch(inputs, classes):\n","    out = torchvision.utils.make_grid(inputs)\n","    imshow(out, title=[class_names[x] for x in classes])\n","\n","# Get a batch of training data\n","inputs, classes,paths = next(iter(trainloader))\n","show_databatch(inputs, classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AgPQ9NcmOMKs","colab_type":"code","colab":{}},"source":["# Load the pretrained model from pytorch\n","dense121 = models.densenet121(pretrained=True)\n","print(dense121 )\n","print('Output Layer of Densenet121 : ', dense121 .classifier.out_features) # 1000 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jajd0qMoOP1M","colab_type":"code","colab":{}},"source":["print(dense121.classifier)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H6mXG-u_OTIN","colab_type":"code","colab":{}},"source":["num_features = dense121.classifier.in_features\n","features = list(dense121.classifier.children())[:-1] # Remove last layer\n","print(features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ooHlT6s1OZKH","colab_type":"code","colab":{}},"source":["# Freeze training for all layers\n","for param in dense121.features.parameters():\n","    param.require_grad = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EqngHf2fObI2","colab_type":"code","colab":{}},"source":["features.extend([nn.Linear(num_features, len(class_names))])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3t-kX_czOcyc","colab_type":"code","colab":{}},"source":["dense121.classifier = nn.Sequential(*features)\n","print(dense121)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W5MUNFzeOhvP","colab_type":"code","colab":{}},"source":["Epochs = 100\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(dense121.parameters(), lr=0.001, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OiCiah7bOnTI","colab_type":"code","colab":{}},"source":["from tqdm import tqdm\n","\n","#if you have gpu then you need to convert the network and data to cuda\n","#the easiest way is to first check for device and then convert network and data to device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","dense121.to(device)\n","\n","dense121.train()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjm-8oXdPbqr","colab_type":"code","colab":{}},"source":["\n","for epoch in range(Epochs):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    pbar = tqdm(enumerate(trainloader))\n","    for i, data in pbar:\n","        # get the inputs\n","        inputs, labels,paths = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n","        # because PyTorch accumulates the gradients on subsequent backward passes. \n","        # This is convenient while training RNNs. \n","        # So, the default action is to accumulate the gradients on every loss.backward() call\n","\n","        # forward + backward + optimize\n","        outputs = dense121(inputs)               #----> forward pass\n","        loss = criterion(outputs, labels)   #----> compute loss\n","        loss.backward()                     #----> backward pass\n","        optimizer.step()                    #----> weights update\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        \n","    torch.save(dense121.state_dict(), 'checkpoint_'+str(epoch)+'.pth')\n","    \n","\n","print('Finished Training')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OzZgWhjlQAtX","colab_type":"code","colab":{}},"source":["#Evaluation\n","dense121.load_state_dict(torch.load('checkpoint_99.pth'))\n","dense121.eval()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qWINISiBYDr2","colab_type":"code","colab":{}},"source":["dataiter = iter(testloader)\n","images, labels, paths = dataiter.next()\n","show_databatch(images, labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8aZf5bJ7YLS-","colab_type":"code","colab":{}},"source":["images, labels = images.to(device), labels.to(device) #-->convert test image to cuda (if available)\n","outputs = dense121(images)                               #--> forward pass\n","_, predicted = torch.max(outputs, 1)\n","\n","print('Predicted: ', ' '.join('%5s' % class_names[predicted[j]]\n","                              for j in range(len(images))))\n","print('Ground Truth: ', ' '.join('%5s' % class_names[labels[j]]\n","                              for j in range(len(images))))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pQFBu55TZB4S","colab_type":"code","colab":{}},"source":["mid_pred =[]\n","high_pred =[]\n","low_pred =[]\n","\n","batch_size =8\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels,paths = data\n","        #print(paths)\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = dense121(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        for k in range(batch_size):\n","          if(predicted[k]==0):\n","            mid_pred.append(paths[k])\n","          if(predicted[k]==1):\n","            high_pred.append(paths[k])\n","          if(predicted[k]==2):\n","            low_pred.append(paths[k])\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","       \n","\n","print('Accuracy of the network on the 528 test images: %d %%' % (\n","    100 * correct / total))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vHB7GesLZYLp","colab_type":"code","colab":{}},"source":["nb_classes = 3\n","\n","confusion_matrix = torch.zeros(nb_classes, nb_classes)\n","with torch.no_grad():\n","    for i, (inputs, classes,paths) in enumerate(testloader):\n","        inputs = inputs.to(device)\n","        classes = classes.to(device)\n","        outputs = dense121(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        for t, p in zip(classes.view(-1), preds.view(-1)):\n","                confusion_matrix[t.long(), p.long()] += 1\n","\n","print(confusion_matrix)"],"execution_count":0,"outputs":[]}]}